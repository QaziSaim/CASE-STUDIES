{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSX5szt+bh4LM2xfv/wGHY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QaziSaim/CASE-STUDIES/blob/main/LangChain_Documentation_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
        "%pip install -U langchain-google-genai\n",
        "%pip install -qU langchain-huggingface\n",
        "%pip install -qU langchain-pinecone"
      ],
      "metadata": {
        "id": "Tu5Nfdg537Dy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cYmxdUnq22y9"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "langsmith_api = userdata.get('langsmith_api')\n",
        "gemini_api = userdata.get('GEMINI_API')\n",
        "hugging_face_api = userdata.get('HUGGINGFACE_API')\n",
        "pinecone_api_key = userdata.get('PINECONE_API')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ['LANGSMITH_TRACING'] = 'true'\n",
        "os.environ['LANGSMITH_API_KEY'] = langsmith_api\n",
        "os.environ[\"GOOGLE_API_KEY\"]  = gemini_api\n",
        "os.environ['HUGGINGFACE_API_KEY'] = hugging_face_api\n",
        "os.environ['PINECONE_API_KEY'] = pinecone_api_key"
      ],
      "metadata": {
        "id": "idu8nldg3Lss"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mQmAXheq3o2X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm.invoke('Do you know about decoder only model??')"
      ],
      "metadata": {
        "id": "3DRng67t4AJq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "rTuuMfgo4Rbw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install \"pinecone[grpc]\"\n",
        "# Serverless index\n",
        "# from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "# from pinecone import ServerlessSpec\n",
        "\n",
        "# pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# pc.create_index(\n",
        "#   name=\"rag-experiment\",\n",
        "#   dimension=768,\n",
        "#   metric=\"cosine\",\n",
        "#   spec=ServerlessSpec(\n",
        "#     cloud=\"aws\",\n",
        "#     region=\"us-east-1\",\n",
        "#   ),\n",
        "#   deletion_protection=\"disabled\"\n",
        "# )\n",
        "\n",
        "# Pod-based index\n",
        "# from pinecone.grpc import PineconeGRPC as Pinecone, PodSpec\n",
        "\n",
        "# pc = Pinecone(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "# pc.create_index(\n",
        "#   name=\"docs-example2\",\n",
        "#   dimension=1536,\n",
        "#   metric=\"cosine\",\n",
        "#   spec=PodSpec(\n",
        "#     environment=\"us-west1-gcp\",\n",
        "#     pod_type=\"p1.x1\",\n",
        "#     pods=1,\n",
        "#   ),\n",
        "#   deletion_protection=\"disabled\"\n",
        "# )"
      ],
      "metadata": {
        "id": "n1C-STyh5tNe"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "index = pc.Index('rag-experiment')\n",
        "\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
      ],
      "metadata": {
        "id": "0DM1T-1E48pv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRsjX8yL5hmp",
        "outputId": "67119e11-af5f-4633-f1c7-489db85fae3c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\n",
        "        web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "        bs_kwargs=dict(\n",
        "            parse_only = bs4.SoupStrainer(\n",
        "                class_ = ('post-content','post-title','post-header')\n",
        "            )\n",
        "        ),\n",
        ")"
      ],
      "metadata": {
        "id": "k3TrlwXH7Lty"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "kAzO2pqd7ib6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "wYWnoeA4733b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,chunk_overlap = 200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "c0EVli_07laD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_  = vector_store.add_documents(documents=all_splits)"
      ],
      "metadata": {
        "id": "Oe3jAup5725Z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull('rlm/rag-prompt')"
      ],
      "metadata": {
        "id": "lSlLgUho8Byc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  question:str\n",
        "  context:List[Document]\n",
        "  answer:str"
      ],
      "metadata": {
        "id": "moWOVSL-8XMf"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(state:State):\n",
        "  retrieved_docs = vector_store.similarity_search(state['question'])\n",
        "  return {'context':retrieved_docs}"
      ],
      "metadata": {
        "id": "tOes6qFJ8jyD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state:State):\n",
        "  docs_content = '\\n\\n'.join(doc.page_content for doc in state['context'])\n",
        "  message = prompt.invoke({'question':state['question'],'context':docs_content})\n",
        "  response = llm.invoke(message)\n",
        "  return {'answer':response.content}"
      ],
      "metadata": {
        "id": "iHvyI4rc84Uo"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State).add_sequence([retrieve,generate])\n",
        "graph_builder.add_edge(START,'retrieve')\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "P3Vlh83V9Wr3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({'question':'What is Task Decomposition?'})\n",
        "print(response['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VusKN-_n9qDa",
        "outputId": "0a083cb6-3cd6-4f95-cf62-6762d3123ea3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task decomposition is a technique where a complex task is broken down into smaller, simpler, and more manageable steps. This process, often facilitated by methods like Chain of Thought (CoT), helps models address difficult problems by thinking step-by-step. It transforms large tasks into multiple manageable sub-tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MmY-Jiiv90uR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}